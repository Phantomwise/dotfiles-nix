#!/usr/bin/env python3

# Description: Matroska metadata writer.
# Dependencies: yt-dlp, mkvpropedit, mkvextract, mkvmerge
# Usage: run in directory with .mkv / .webm files.
# AI Disclaimer: This script was generated by an AI language model.
# Patched: improved logging, namespace-robust XML parsing, show subprocess errors,
#         and configurable yt-dlp extra args for cookies / player variant.

import subprocess
import sys
import shutil
import json
import re
import os
import tempfile
import shlex
from xml.etree import ElementTree as ET
from xml.sax.saxutils import escape as xml_escape
import logging

REQUIRED_CMDS = ["yt-dlp", "mkvpropedit", "mkvextract", "mkvmerge"]

logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
logger = logging.getLogger("matroska_metadata_writer")

# yt-dlp extra args (only extra arguments like cookies, player variant, etc.)
# Edit this list to change cookies / player variant without modifying the metadata flags.
# Default example: use browser cookies from Firefox and the TV JS player variant.
# You can override at runtime by setting the environment variable YT_DLP_EXTRA_ARGS
# to a shell-like string, e.g.:
#   export YT_DLP_EXTRA_ARGS='--cookies-from-browser firefox --extractor-args "youtube:player_js_variant=tv"'
yt_dlp_extra_args = [
    "--cookies-from-browser", "firefox",
    "--extractor-args", "youtube:player_js_variant=tv"
]

# Allow override from environment (parsed with shlex so quoting works)
env_extra = os.environ.get("YT_DLP_EXTRA_ARGS")
if env_extra:
    try:
        yt_dlp_extra_args = shlex.split(env_extra)
        logger.info("Using YT_DLP_EXTRA_ARGS from environment: %s", yt_dlp_extra_args)
    except Exception as e:
        logger.warning("Failed to parse YT_DLP_EXTRA_ARGS env var, using defaults. Error: %s", e)

def die(msg, code=2):
    logger.error(msg)
    sys.exit(code)

def check_deps():
    missing = []
    for c in REQUIRED_CMDS:
        if shutil.which(c) is None:
            missing.append(c)
    if missing:
        die("Missing required commands: " + ", ".join(missing))

def is_matroska(file):
    # fast path: file extension
    ext = file.lower().rsplit(".", 1)[-1]
    if ext in ("mkv", "webm"):
        return True
    # fallback to mkvmerge inspection
    try:
        out = subprocess.check_output(["mkvmerge", "-J", file], stderr=subprocess.DEVNULL)
        j = json.loads(out)
        cont = j.get("container") or j.get("file", {}).get("container") or ""
        return "matroska" in cont.lower() or "webm" in cont.lower()
    except Exception:
        try:
            txt = subprocess.check_output(["mkvmerge", "-i", file], stderr=subprocess.DEVNULL, text=True)
            return "matroska" in txt.lower() or "webm" in txt.lower()
        except Exception:
            return False

def _parse_first_json(stdout):
    """Return the first JSON object found in stdout (handles multiple JSON lines)."""
    if not stdout:
        return None
    for line in stdout.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            return json.loads(line)
        except Exception:
            continue
    try:
        return json.loads(stdout)
    except Exception:
        return None

def extract_youtube_metadata(yid):
    """
    Use yt-dlp plus yt_dlp_extra_args to fetch metadata (-j). Returns dict with
    title/artist/description/date (ISO YYYY-MM-DD if upload_date available).
    """
    url = f"https://www.youtube.com/watch?v={yid}"
    cmd = ["yt-dlp"] + yt_dlp_extra_args + ["-j", url]

    try:
        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=False)
    except FileNotFoundError:
        logger.debug("yt-dlp not found on PATH")
        return {"title": "", "artist": "", "description": "", "date": ""}

    stdout = proc.stdout or ""
    stderr = proc.stderr or ""
    if stderr:
        logger.debug("yt-dlp stderr: %s", stderr.strip())

    parsed = _parse_first_json(stdout)
    if not parsed:
        logger.debug("yt-dlp produced no usable JSON on stdout")
        return {"title": "", "artist": "", "description": "", "date": ""}

    # If a playlist-like object with "entries" was returned, take the first entry
    if isinstance(parsed, dict) and "entries" in parsed and parsed.get("entries"):
        parsed = parsed["entries"][0] or parsed

    j = parsed
    title = j.get("title") or ""
    artist = (
        j.get("uploader_id")
        or j.get("channel_id")
        or j.get("uploader")
        or j.get("channel")
        or j.get("creator")
        or ""
    )
    desc = j.get("description") or ""
    date_raw = j.get("upload_date") or j.get("release_date") or ""
    if re.match(r"^\d{8}$", date_raw):
        date = f"{date_raw[0:4]}-{date_raw[4:6]}-{date_raw[6:8]}"
    else:
        date = date_raw or ""
    # Log a short debug summary of what we found
    logger.debug("yt-dlp JSON fetched: title=%s artist=%s date=%s", title or "<none>", artist or "<none>", date or "<none>")
    return {"title": title, "artist": artist, "description": desc, "date": date}

def extract_existing_tags_to_file(video_file, tags_file):
    """Extract existing tags from video file to XML file using mkvextract."""
    try:
        # mkvextract tags outputs XML to stdout; capture it
        result = subprocess.run(
            ["mkvextract", "tags", video_file],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        logger.debug("mkvextract rc=%s", result.returncode)
        if result.stderr:
            logger.debug("mkvextract stderr: %s", result.stderr.strip())

        # If stdout contains XML, write it regardless of returncode (some versions/tools may use non-zero)
        if result.stdout and ("<Tags" in result.stdout or "<?xml" in result.stdout):
            with open(tags_file, 'w', encoding='utf-8') as f:
                f.write(result.stdout)
            logger.info("Tags extracted to %s (mkvextract stdout)", tags_file)
            return True
        else:
            logger.warning("mkvextract did not produce tags XML (rc=%s). stdout_len=%d", result.returncode, len(result.stdout or ""))
            return False

    except FileNotFoundError:
        logger.error("mkvextract not found")
        return False
    except Exception as e:
        logger.debug("Exception in extract_existing_tags_to_file: %s", e)
        return False

def validate_xml_file(xml_file):
    """Validate that the XML file is well-formed."""
    try:
        if not os.path.exists(xml_file) or os.path.getsize(xml_file) == 0:
            return False
        ET.parse(xml_file)
        return True
    except Exception as e:
        logger.debug("XML validation failed for %s: %s", xml_file, e)
        return False

def _localname(tag):
    """Return the localname of an XML tag even when namespaced."""
    if tag is None:
        return ""
    return tag.rsplit("}", 1)[-1] if "}" in tag else tag

def find_child_by_localname(parent, name):
    for c in list(parent):
        if _localname(c.tag) == name:
            return c
    return None

def parse_tags_file(path):
    if not os.path.exists(path) or os.path.getsize(path) == 0:
        return []
    try:
        tree = ET.parse(path)
    except Exception as e:
        logger.debug("Failed to parse tags XML %s: %s", path, e)
        return []
    root = tree.getroot()
    tags = []
    # Find Tag elements regardless of namespace/localname
    for elem in root.iter():
        if _localname(elem.tag) != "Tag":
            continue
        tag = elem
        targets_el = find_child_by_localname(tag, "Targets")
        targets = []
        if targets_el is not None:
            for child in list(targets_el):
                tname = _localname(child.tag)
                targets.append((tname, child.text or ""))
        simples = []
        for simple in [c for c in list(tag) if _localname(c.tag) == "Simple"]:
            name_el = find_child_by_localname(simple, "Name")
            string_el = find_child_by_localname(simple, "String")
            taglang_el = find_child_by_localname(simple, "TagLanguageIETF")
            name = (name_el.text or "") if name_el is not None else ""
            val = ""
            if string_el is not None:
                # String may include CDATA or nested text nodes
                val = "".join(string_el.itertext())
            taglang = taglang_el.text if taglang_el is not None else None
            if name:
                simples.append((name, val, taglang))
        tags.append({"targets": targets, "simples": simples})
    return tags

def write_merged_tags_to_file(existing_tags, new_tags_map, outpath):
    """Write merged tags to XML file, preserving all existing non-global tags."""
    # Find or create global tag (empty targets)
    global_index = None
    for i, t in enumerate(existing_tags):
        if not t["targets"]:
            global_index = i
            break

    if global_index is None:
        # Insert new global tag at the beginning
        existing_tags.insert(0, {"targets": [], "simples": []})
        global_index = 0

    # Only merge new metadata into the global tag
    existing_global = {name: (val, taglang) for (name, val, taglang) in existing_tags[global_index]["simples"]}

    # Update with new tags
    for k, v in new_tags_map.items():
        existing_global[k] = (v, None)

    # Rebuild the global tag's simples
    merged_simples = []
    seen = set()

    # Preserve existing global tags, updating with new values where they exist
    for name, val, taglang in existing_tags[global_index]["simples"]:
        val2, taglang2 = existing_global.get(name, (val, taglang))
        merged_simples.append((name, val2, taglang2))
        seen.add(name)

    # Add any new tags that weren't in existing global tags
    for name in new_tags_map:
        if name not in seen:
            merged_simples.append((name, existing_global[name][0], existing_global[name][1]))

    # Update the global tag
    existing_tags[global_index]["simples"] = merged_simples

    # Write ALL tags (global + track-specific)
    with open(outpath, "w", encoding="utf-8") as f:
        f.write('<?xml version="1.0"?>\n')
        f.write('<Tags>\n')
        for tag in existing_tags:
            f.write('  <Tag>\n')
            if not tag["targets"]:
                f.write('    <Targets />\n')
            else:
                f.write('    <Targets>\n')
                for tname, tval in tag["targets"]:
                    # tname is expected to be a valid element name like "TrackUID" or similar.
                    # We escape the content but not the element name.
                    f.write(f'      <{tname}>{xml_escape(tval or "")}</{tname}>\n')
                f.write('    </Targets>\n')
            for name, val, taglang in tag["simples"]:
                f.write('    <Simple>\n')
                f.write(f'      <Name>{xml_escape(name)}</Name>\n')
                safe = (val or "").replace(']]>', ']]]]><![CDATA[>')
                f.write(f'      <String><![CDATA[{safe}]]></String>\n')
                if taglang:
                    f.write(f'      <TagLanguageIETF>{xml_escape(taglang)}</TagLanguageIETF>\n')
                f.write('    </Simple>\n')
            f.write('  </Tag>\n')
        f.write('</Tags>\n')

def apply_tags_from_file(video_file, tags_file, title):
    """Apply tags from XML file to video using mkvpropedit."""
    args = ["mkvpropedit", video_file, "--tags", f"all:{tags_file}"]
    if title:
        args += ["--edit", "info", "--set", f"title={title}"]
    try:
        # capture output to show errors if any
        proc = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if proc.returncode == 0:
            logger.info("mkvpropedit applied tags successfully")
            return True
        else:
            logger.error("mkvpropedit failed (rc=%s). stdout=%s stderr=%s", proc.returncode, proc.stdout.strip(), proc.stderr.strip())
            return False
    except FileNotFoundError:
        logger.error("mkvpropedit not found")
        return False
    except Exception as e:
        logger.debug("Exception running mkvpropedit: %s", e)
        return False

def process_file(file):
    logger.info("Processing: %s", file)
    if not is_matroska(file):
        logger.warning("Not a Matroska/WebM container; skipping: %s", file)
        return

    m = re.search(r'\[([A-Za-z0-9_-]{11})\]', file)
    if not m:
        logger.error("Could not extract YouTube ID from filename: %s", file)
        return

    yid = m.group(1)
    logger.info("YouTube ID: %s", yid)

    meta = extract_youtube_metadata(yid)
    logger.info("Title: %s", meta.get('title') or '<none>')
    logger.info("Artist: %s", meta.get('artist') or '<none>')
    logger.info("Date: %s", meta.get('date') or '<none>')

    # Create temp file path based on video filename
    safe_filename = re.sub(r'[^\w\-_.]', '_', file)
    tags_file = os.path.join('/tmp', f"{safe_filename}.tags.xml")

    try:
        # Step 1: Extract existing tags to temp XML file
        if extract_existing_tags_to_file(file, tags_file):
            logger.info("Existing tags extracted successfully.")
        else:
            logger.warning("Could not extract existing tags; creating empty tags file.")
            with open(tags_file, 'w', encoding='utf-8') as f:
                f.write('<?xml version="1.0"?>\n<Tags>\n</Tags>\n')

        # Step 2: Validate extracted XML
        if not validate_xml_file(tags_file):
            logger.warning("Extracted tags XML is invalid; creating empty tags file.")
            with open(tags_file, 'w', encoding='utf-8') as f:
                f.write('<?xml version="1.0"?>\n<Tags>\n</Tags>\n')

        # Step 3: Parse existing tags and merge with new YouTube metadata
        existing_tags = parse_tags_file(tags_file)
        new_tags = {
            "TITLE": meta.get("title", ""),
            "ARTIST": meta.get("artist", ""),
            "DESCRIPTION": meta.get("description", ""),
            # COMMENT previously held a single-line truncated version of the description:
            # "COMMENT": " ".join(meta.get("description", "").splitlines())[:240],
            # That line has been commented out so DESCRIPTION is kept but COMMENT will not be added.
            "DATE_RELEASED": meta.get("date", "")
        }

        # Remove empty tags
        new_tags = {k: v for k, v in new_tags.items() if v}

        # Step 4: Write merged tags back to temp file
        write_merged_tags_to_file(existing_tags, new_tags, tags_file)

        # Step 5: Validate merged XML
        if not validate_xml_file(tags_file):
            logger.error("Merged tags XML is invalid; aborting.")
            return

        logger.info("Tags merged successfully (written to %s).", tags_file)

        # Step 6: Apply tags from temp file to video
        if apply_tags_from_file(file, tags_file, meta.get("title", "")):
            logger.info("MKV/WebM metadata updated successfully (merged tags + title).")
        else:
            logger.error("Failed to apply tags to video file. See mkvpropedit output above for details.")

    finally:
        # Step 7: Clean up temp file
        try:
            if os.path.exists(tags_file):
                os.remove(tags_file)
        except Exception:
            pass

def main():
    check_deps()
    for fname in sorted([f for f in os.listdir(".") if f.lower().endswith((".mkv", ".webm"))]):
        if os.path.isfile(fname):
            process_file(fname)
            print()

if __name__ == "__main__":
    main()